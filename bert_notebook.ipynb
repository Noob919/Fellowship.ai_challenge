{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-23T21:30:31.294100Z","iopub.execute_input":"2021-12-23T21:30:31.294376Z","iopub.status.idle":"2021-12-23T21:30:31.305512Z","shell.execute_reply.started":"2021-12-23T21:30:31.294346Z","shell.execute_reply":"2021-12-23T21:30:31.304599Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"Reading the dataset","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/yelp-review-polarity/yelp_review_polarity_csv/yelp_review_polarity_csv/train.csv')\ntest_df  = pd.read_csv('/kaggle/input/yelp-review-polarity/yelp_review_polarity_csv/yelp_review_polarity_csv/test.csv')","metadata":{"execution":{"iopub.status.busy":"2021-12-23T21:30:39.548058Z","iopub.execute_input":"2021-12-23T21:30:39.548611Z","iopub.status.idle":"2021-12-23T21:30:43.218151Z","shell.execute_reply.started":"2021-12-23T21:30:39.548573Z","shell.execute_reply":"2021-12-23T21:30:43.217412Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"train_df.columns = ['Rating','Review']\ntest_df.columns = ['Rating', 'Review']","metadata":{"execution":{"iopub.status.busy":"2021-12-23T21:30:46.187963Z","iopub.execute_input":"2021-12-23T21:30:46.188231Z","iopub.status.idle":"2021-12-23T21:30:46.192797Z","shell.execute_reply.started":"2021-12-23T21:30:46.188201Z","shell.execute_reply":"2021-12-23T21:30:46.192087Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"train_df['Rating'] = train_df['Rating'].replace(2,1)\ntest_df['Rating'] = test_df['Rating'].replace(2,1)","metadata":{"execution":{"iopub.status.busy":"2021-12-23T21:30:51.502380Z","iopub.execute_input":"2021-12-23T21:30:51.503296Z","iopub.status.idle":"2021-12-23T21:30:51.516099Z","shell.execute_reply.started":"2021-12-23T21:30:51.503244Z","shell.execute_reply":"2021-12-23T21:30:51.515249Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"train_df['Rating'] = train_df['Rating'].replace(1,0)\ntest_df['Rating'] = test_df['Rating'].replace(1,0)","metadata":{"execution":{"iopub.status.busy":"2021-12-23T21:30:54.566040Z","iopub.execute_input":"2021-12-23T21:30:54.566546Z","iopub.status.idle":"2021-12-23T21:30:54.577023Z","shell.execute_reply.started":"2021-12-23T21:30:54.566504Z","shell.execute_reply":"2021-12-23T21:30:54.576106Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2021-12-23T00:03:10.686131Z","iopub.execute_input":"2021-12-23T00:03:10.686824Z","iopub.status.idle":"2021-12-23T00:03:10.692369Z","shell.execute_reply.started":"2021-12-23T00:03:10.686788Z","shell.execute_reply":"2021-12-23T00:03:10.691692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Model","metadata":{}},{"cell_type":"code","source":"from transformers import BertTokenizer, TFBertForSequenceClassification\nfrom transformers import InputExample, InputFeatures\n\nmodel = TFBertForSequenceClassification.from_pretrained(\"bert-base-uncased\")\ntokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")","metadata":{"execution":{"iopub.status.busy":"2021-12-23T21:31:04.780028Z","iopub.execute_input":"2021-12-23T21:31:04.780941Z","iopub.status.idle":"2021-12-23T21:31:10.075857Z","shell.execute_reply.started":"2021-12-23T21:31:04.780896Z","shell.execute_reply":"2021-12-23T21:31:10.075106Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-12-23T21:31:19.341576Z","iopub.execute_input":"2021-12-23T21:31:19.342136Z","iopub.status.idle":"2021-12-23T21:31:19.366982Z","shell.execute_reply.started":"2021-12-23T21:31:19.342098Z","shell.execute_reply":"2021-12-23T21:31:19.366101Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"def convert_data_to_examples(train, test, DATA_COLUMN, LABEL_COLUMN): \n  train_InputExamples = train.apply(lambda x: InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this case\n                                                          text_a = x[DATA_COLUMN], \n                                                          text_b = None,\n                                                          label = x[LABEL_COLUMN]), axis = 1)\n\n  validation_InputExamples = test.apply(lambda x: InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this case\n                                                          text_a = x[DATA_COLUMN], \n                                                          text_b = None,\n                                                          label = x[LABEL_COLUMN]), axis = 1)\n  \n  return train_InputExamples, validation_InputExamples\n\n  train_InputExamples, validation_InputExamples = convert_data_to_examples(train, \n                                                                           test, \n                                                                           'DATA_COLUMN', \n                                                                           'LABEL_COLUMN')\n  \ndef convert_examples_to_tf_dataset(examples, tokenizer, max_length=128):\n    features = [] # -> will hold InputFeatures to be converted later\n\n    for e in examples:\n        # Documentation is really strong for this method, so please take a look at it\n        input_dict = tokenizer.encode_plus(\n            e.text_a,\n            add_special_tokens=True,\n            max_length=max_length, # truncates if len(s) > max_length\n            return_token_type_ids=True,\n            return_attention_mask=True,\n            pad_to_max_length=True, # pads to the right by default # CHECK THIS for pad_to_max_length\n            truncation=True\n        )\n\n        input_ids, token_type_ids, attention_mask = (input_dict[\"input_ids\"],\n            input_dict[\"token_type_ids\"], input_dict['attention_mask'])\n\n        features.append(\n            InputFeatures(\n                input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, label=e.label\n            )\n        )\n\n    def gen():\n        for f in features:\n            yield (\n                {\n                    \"input_ids\": f.input_ids,\n                    \"attention_mask\": f.attention_mask,\n                    \"token_type_ids\": f.token_type_ids,\n                },\n                f.label,\n            )\n\n    return tf.data.Dataset.from_generator(\n        gen,\n        ({\"input_ids\": tf.int32, \"attention_mask\": tf.int32, \"token_type_ids\": tf.int32}, tf.int64),\n        (\n            {\n                \"input_ids\": tf.TensorShape([None]),\n                \"attention_mask\": tf.TensorShape([None]),\n                \"token_type_ids\": tf.TensorShape([None]),\n            },\n            tf.TensorShape([]),\n        ),\n    )\n\n\nDATA_COLUMN = 'DATA_COLUMN'\nLABEL_COLUMN = 'LABEL_COLUMN'\n","metadata":{"execution":{"iopub.status.busy":"2021-12-23T21:31:32.236216Z","iopub.execute_input":"2021-12-23T21:31:32.236521Z","iopub.status.idle":"2021-12-23T21:31:32.248438Z","shell.execute_reply.started":"2021-12-23T21:31:32.236490Z","shell.execute_reply":"2021-12-23T21:31:32.247694Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"train_df = train_df[0:100000]\ntest_df  = test_df[0:9000]","metadata":{"execution":{"iopub.status.busy":"2021-12-23T21:38:05.400241Z","iopub.execute_input":"2021-12-23T21:38:05.400834Z","iopub.status.idle":"2021-12-23T21:38:05.406956Z","shell.execute_reply.started":"2021-12-23T21:38:05.400791Z","shell.execute_reply":"2021-12-23T21:38:05.405295Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf","metadata":{"execution":{"iopub.status.busy":"2021-12-23T21:31:44.269815Z","iopub.execute_input":"2021-12-23T21:31:44.270598Z","iopub.status.idle":"2021-12-23T21:31:44.274392Z","shell.execute_reply.started":"2021-12-23T21:31:44.270559Z","shell.execute_reply":"2021-12-23T21:31:44.273556Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"train_InputExamples, validation_InputExamples = convert_data_to_examples(train_df, test_df, 'Review', 'Rating')\n\ntrain_data = convert_examples_to_tf_dataset(list(train_InputExamples), tokenizer)\ntrain_data = train_data.shuffle(100).batch(32).repeat(2)\n\nvalidation_data = convert_examples_to_tf_dataset(list(validation_InputExamples), tokenizer)\nvalidation_data = validation_data.batch(32)","metadata":{"execution":{"iopub.status.busy":"2021-12-23T21:38:15.680546Z","iopub.execute_input":"2021-12-23T21:38:15.680906Z","iopub.status.idle":"2021-12-23T21:46:06.079846Z","shell.execute_reply.started":"2021-12-23T21:38:15.680866Z","shell.execute_reply":"2021-12-23T21:46:06.079111Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer='adam', loss=\"sparse_categorical_crossentropy\", metrics= ['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-12-23T21:46:34.146124Z","iopub.execute_input":"2021-12-23T21:46:34.146381Z","iopub.status.idle":"2021-12-23T21:46:34.158298Z","shell.execute_reply.started":"2021-12-23T21:46:34.146353Z","shell.execute_reply":"2021-12-23T21:46:34.157452Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"model.fit(train_data, epochs=3, validation_data=validation_data)","metadata":{"execution":{"iopub.status.busy":"2021-12-23T21:46:45.203971Z","iopub.execute_input":"2021-12-23T21:46:45.204257Z","iopub.status.idle":"2021-12-23T23:29:37.123661Z","shell.execute_reply.started":"2021-12-23T21:46:45.204227Z","shell.execute_reply":"2021-12-23T23:29:37.122633Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2021-12-23T21:26:41.622724Z","iopub.execute_input":"2021-12-23T21:26:41.622993Z","iopub.status.idle":"2021-12-23T21:26:41.626780Z","shell.execute_reply.started":"2021-12-23T21:26:41.622962Z","shell.execute_reply":"2021-12-23T21:26:41.625979Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"metrics_df  = (pd.DataFrame({'loss':[2.0344e-04,1.1921e-07],'accuracy':[1.0000,1.0000],'val_loss':[1.1921e-07,1.1921e-07],'val_accuracy':[1.0000,1.000]}))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(metrics_df['loss'], label = 'loss for Train set')\nplt.plot(metrics_df['val_loss'], label = 'loss for Test Set')\nplt.title('loss of our model')\nplt.ylabel('loss')\nplt.xlabel('epochs')\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2021-12-23T23:37:38.149386Z","iopub.execute_input":"2021-12-23T23:37:38.149696Z","iopub.status.idle":"2021-12-23T23:37:38.403472Z","shell.execute_reply.started":"2021-12-23T23:37:38.149665Z","shell.execute_reply":"2021-12-23T23:37:38.402746Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"plt.plot(metrics_df['accuracy'], label = 'accuracy for Train set')\nplt.plot(metrics_df['val_accuracy'], label = 'accuracy for Test Set')\nplt.title('accuracy of our model')\nplt.ylabel('Accuracy')\nplt.xlabel('epochs')\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2021-12-23T23:38:41.929148Z","iopub.execute_input":"2021-12-23T23:38:41.929498Z","iopub.status.idle":"2021-12-23T23:38:42.226503Z","shell.execute_reply.started":"2021-12-23T23:38:41.929456Z","shell.execute_reply":"2021-12-23T23:38:42.225556Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}